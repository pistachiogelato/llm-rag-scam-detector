from sentence_transformers import SentenceTransformer
from huggingface_hub import InferenceClient
import numpy as np
import faiss
import os
import logging
import faiss
from dotenv import load_dotenv
from typing import List
import re 
from collections import defaultdict

load_dotenv()

# Initialize the embedding model globally
encoder = SentenceTransformer('paraphrase-MiniLM-L6-v2')

def encode_text(text: str) -> np.ndarray:
    """
    Convert input text into a vector embedding using the SentenceTransformer model.
    
    Args:
        text (str): The input text to encode.
    
    Returns:
        np.ndarray: A numpy array representing the text embedding.
    """
    return encoder.encode(text, convert_to_tensor=False).astype('float32')

def encode_text_batch(texts: List[str], batch_size: int = 32) -> np.ndarray:
    """
    æ‰¹é‡ç¼–ç æ–‡æœ¬
    """
    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        batch_embeddings = encoder.encode(batch, convert_to_numpy=True)
        embeddings.append(batch_embeddings)
    return np.vstack(embeddings)

def build_faiss_index(vectors: np.ndarray) -> faiss.IndexFlatL2:
    """
    Build a FAISS index for efficient similarity search over a set of vectors.
    
    Args:
        vectors (np.ndarray): Array of shape (n_samples, vector_dim) containing embeddings.
    
    Returns:
        faiss.IndexFlatL2: A FAISS index for L2 distance-based retrieval.
    """
    #dim = vectors.shape[1]  # Vector dimension
    #dim = vectors.shape[1] if vectors.shape[1] else 384
    dim = encoder.get_sentence_embedding_dimension()
    index = faiss.IndexFlatL2(dim)
    print(f"Building index with dimension: {dim}")
    print(f"Input vectors shape: {vectors.shape}")
    index.add(vectors)
    return index

def retrieve_similar(query_text: str, index: faiss.IndexFlatL2, scam_texts: list, k: int = 3) -> list:
    """
    ä¼˜åŒ–ç›¸ä¼¼åº¦æ£€ç´¢å‡½æ•°
    """
    if not scam_texts:
        logging.warning("No scam texts available for retrieval")
        return []
        
    query_vec = encode_text(query_text)
    query_vec = query_vec.reshape(1, -1)
    
    try:
        # ä¿®æ”¹ç›¸ä¼¼åº¦é˜ˆå€¼
        distances, indices = index.search(query_vec, k)
        logging.info(f"Query: {query_text}")
        logging.info(f"Distances: {distances}")
        logging.info(f"Indices: {indices}")
        
        # è®¾ç½®è·ç¦»é˜ˆå€¼ï¼Œè·ç¦»è¶Šå°è¶Šç›¸ä¼¼
        distance_threshold = 2.0
        valid_indices = [
            i for i, d in zip(indices[0], distances[0]) 
            if i >= 0 and i < len(scam_texts) and d < distance_threshold
        ]
        
        similar_texts = [scam_texts[i] for i in valid_indices]
        logging.info(f"Found {len(similar_texts)} similar texts")
        return similar_texts
    except Exception as e:
        logging.error(f"Error during similarity search: {e}")
        return []

def llm_predict(prompt: str) -> str:
    """
    Generate a response from the LLM API based on the provided prompt.
    
    Args:
        prompt (str): The input prompt for the LLM.
    
    Returns:
        str: The generated text from the LLM.
    
    Raises:
        Exception: If API token is missing or LLM call fails.
    """
    api_token = os.getenv("API_TOKEN")
    if not api_token:
        logging.error("API_TOKEN is missing!")
        raise Exception("API_TOKEN is not set in environment variables.")

    try:
        client = InferenceClient(provider="sambanova", api_key=api_token)
        messages = [{"role": "user", "content": prompt}]
        logging.info(f"Sending request to LLM: {prompt[:100]}...")  #debug
        completion = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-R1",
            messages=messages,
            max_tokens=150
        )
        logging.info("LLM request successful")
        return completion.choices[0].message.content
    except Exception as e:
        logging.error(f"LLM API error: {str(e)}", exc_info=True)  # debug
        raise

def generate_report(user_text: str, retrieved_cases: list) -> str:
    """
    Generate a scam detection report using the user text and retrieved cases.
    
    Args:
        user_text (str): The user-provided text to analyze.
        retrieved_cases (list): List of similar scam examples retrieved.
    
    Returns:
        str: A detailed report from the LLM.
    """
    prompt = (
        f"User message: {user_text}\n"
        f"Related scam examples:\n" + "\n".join(retrieved_cases) +
        "\n\nBased on the above, analyze if the user's message is a scam, explain why, "
        "and provide recommendations."
    )
    return llm_predict(prompt)

def detect_and_generate_report(user_text: str, scam_texts: list, faiss_index: faiss.IndexFlatL2) -> dict:
    """
    ä¼˜åŒ–è¯ˆéª—æ£€æµ‹å’ŒæŠ¥å‘Šç”Ÿæˆ
    """
    try:
        print(f"Processing text: {user_text}")
        print(f"Available scam texts: {len(scam_texts)}")
        
         # 1. æ”¹è¿›å…³é”®è¯æƒé‡ç³»ç»Ÿ
        keyword_patterns = {
        # é‡‘é¢ç›¸å…³æ¨¡å¼ï¼ˆä¿æŒåŸæœ‰ï¼‰
        "money_request": {
            "patterns": [
                (r"send.*?\$?\d+", 0.7),
                (r"send.*?money", 0.7),
                (r"need.*?\$?\d+", 0.6),
                (r"ç»™æˆ‘.*?é’±", 0.7),
                (r"è½¬è´¦.*?\d+", 0.7)
            ],
            "category": "financial"
        },
    
        # ç´§æ€¥ç¨‹åº¦ç›¸å…³ï¼ˆä¿æŒåŸæœ‰ï¼‰
        "urgency": {
            "patterns": [
                (r"urgent|immediately|asap", 0.5),
                (r"ç´§æ€¥|ç«‹å³|é©¬ä¸Š", 0.5)
            ],
            "category": "urgent"
        },

        # æ–°å¢é€šç”¨è¯ˆéª—å…³é”®è¯åˆ†ç±»
        "general_fraud": {
            "patterns": [
                # è‹±æ–‡å…³é”®è¯ï¼ˆåŠ¨æ€ç”Ÿæˆæ¨¡å¼ï¼‰
                *[(rf"\b{kw}\b", weight) for kw, weight in {
                    "account": 0.3, "verify": 0.4, "bank": 0.3,
                    "urgent": 0.5, "immediately": 0.4, "password": 0.5,
                    "login": 0.4, "money": 0.3, "payment": 0.3,
                    "verification": 0.4, "security": 0.3, "secure": 0.3,
                    "update": 0.3, "confirm": 0.3, "important": 0.4,
                    "limited time": 0.4, "expires": 0.4, "suspended": 0.4,
                    "blocked": 0.4, "click": 0.3, "link": 0.3
                }.items()],
                
                # ä¸­æ–‡å…³é”®è¯ï¼ˆç›´æ¥åŒ¹é…ï¼‰
                (r"è´¦æˆ·", 0.3), (r"éªŒè¯", 0.3), (r"é“¶è¡Œ", 0.3),
                (r"ç´§æ€¥", 0.4), (r"ç«‹å³", 0.4), (r"å¯†ç ", 0.5),
                (r"ç™»å½•", 0.4), (r"é’±", 0.3), (r"æ”¯ä»˜", 0.3)
            ],
            "category": "suspicious_keywords"
        }
    }

        
        # 2. æ”¹è¿›æ–‡æœ¬å¤„ç†
        text_lower = user_text.lower()
        matched_patterns = []
        pattern_score = 0.0
        category_scores = defaultdict(float)  # ä½¿ç”¨åˆ†ç±»æœ€é«˜åˆ†

        # 3. è®¡ç®—å…³é”®è¯åŒ¹é…å¾—åˆ†
        for category, data in keyword_patterns.items():
            max_category_score = 0.0
            for pattern, weight in data["patterns"]:
                if re.search(pattern, text_lower):
                    max_category_score = max(max_category_score, weight)
            category_scores[data["category"]] = max_category_score

        pattern_score = sum(category_scores.values())  # æ¯ä¸ªåˆ†ç±»åªå–æœ€é«˜åˆ†
        
        # 4. è·å–ç›¸ä¼¼æ¡ˆä¾‹
        retrieved_cases = retrieve_similar(user_text, faiss_index, scam_texts)
        
        # 5. ä½¿ç”¨ LLM è¿›è¡Œæ·±åº¦åˆ†æ
        if pattern_score > 0.3 or retrieved_cases:  # åªåœ¨æœ‰å¯ç–‘æƒ…å†µæ—¶è°ƒç”¨ LLM
            try:
                llm_prompt = f"""Analyze if this message is a potential scam:
                Message: {user_text}
                
                Consider:
                1. Does it request money or financial information?
                2. Is there urgency or pressure?
                3. Does it mix different languages suspiciously?
                4. Are there any red flags typical of scams?
                
                Similar cases found: {retrieved_cases[:2] if retrieved_cases else 'None'}
                
                Provide a brief analysis and confidence score (0-1).
                """
                
                llm_analysis = llm_predict(llm_prompt)
                
                # è§£æ LLM çš„ç½®ä¿¡åº¦ï¼ˆå‡è®¾ LLM ä¼šåœ¨å›å¤ä¸­åŒ…å«æ•°å­—ç½®ä¿¡åº¦ï¼‰
                
                confidence_match = re.search(r'confidence[:\s]+([0-9.]+)', llm_analysis.lower())
                llm_confidence = float(confidence_match.group(1)) if confidence_match else 0.5
                
                # ç»¼åˆè¯„åˆ† ç½®ä¿¡åº¦å½’ä¸€åŒ–å¤„ç†
                final_confidence = min(max(pattern_score * 0.4 + llm_confidence * 0.6, 0.0), 1.0)
            except Exception as e:
                logging.error(f"LLM analysis failed: {e}")
                final_confidence = pattern_score
                llm_analysis = "LLM analysis unavailable."
        else:
            final_confidence = pattern_score
            llm_analysis = "No significant risk indicators found."
        
        # 6. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        risk_level = "High Risk" if final_confidence > 0.7 else "Medium Risk" if final_confidence > 0.4 else "Low Risk"
        
        # ç‰¹å¾æè¿°ç”Ÿæˆ
        bullet_points = []
        if category_scores.get("financial"):
            bullet_points.append("ğŸ’° Detected financial request patterns")
        if category_scores.get("urgent"):
            bullet_points.append("â° Contains urgent time pressure")
        if len(matched_patterns) > 3:
            bullet_points.append(f"ğŸ” Found {len(matched_patterns)} suspicious keywords")

        # ä¸“ä¸šè‹±æ–‡æŠ¥å‘Šæ¨¡æ¿
        report = f"""
            [Fraud Detection Report]
            Risk Level: {risk_level} (Confidence: {final_confidence*100:.1f}%)

            Key Indicators:
            {'\n'.join(bullet_points) if bullet_points else 'No strong indicators found'}

            Recommendations:
            1. Do NOT transfer money or share sensitive information
            2. Verify the requester's identity through official channels
            3. Report suspicious requests to platform administrators
                    """

        return {
            "scam_detected": final_confidence > 0.5,
            "scam_type": next(iter(category_scores), "unknown"),
            "confidence": round(final_confidence, 2),
            "report": report,
            # ä¿ç•™è°ƒè¯•æ•°æ®
            "_debug": {
                "raw_scores": dict(category_scores),
                "llm_analysis": llm_analysis
            }
        }
        
    except Exception as e:
        logging.error(f"Error in detect_and_generate_report: {e}")
        return {
            "scam_detected": False,
            "scam_type": "error",
            "confidence": 0.0,
            "report": f"Error processing request: {str(e)}",
            "retrieved_cases": [],
            "matched_keywords": []
        }